{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnITccKqxtOq"
   },
   "source": [
    "# 0.Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16169,
     "status": "ok",
     "timestamp": 1735288569929,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "OzSN9gT8PvAW",
    "outputId": "66e98201-1434-42b9-9bed-6161832976c4"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.0\n",
    "!pip install datasets==3.2.0\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1735288570863,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "erkR7rjytKyU"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"Add hugingface token here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm5wZzWNltUt"
   },
   "source": [
    "Mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2053,
     "status": "ok",
     "timestamp": 1735288572913,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "bLLE1nv7jQrn",
    "outputId": "efcdb1b9-2b75-4670-bbf4-b7f947580f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to storage model \n",
    "drive.mount('/content/drive')\n",
    "cache_dir=\"/content/drive/MyDrive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EESH0_Zlx0aA"
   },
   "source": [
    "# 1.Load Llama model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XM9o-REvKNJB"
   },
   "source": [
    "**Download Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37275,
     "status": "ok",
     "timestamp": 1735288610186,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "Wm4xLIyes1oC",
    "outputId": "47c65206-2466-41b8-bdbc-1e1fbe733305"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAedz47yrj9I"
   },
   "source": [
    "# 2.Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1735288610514,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "biBXlJjHFhOR"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1735288611237,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "yUwZGwihEIkR"
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "  {\n",
    "    \"question\": \"Hãy cho tôi biết nội dung của khoá học Generative AI của Nguyễn Mạnh Lực\",\n",
    "    \"answer\": \"Khoá học bao gồm các chủ đề về Generative AI, large language models, langchain, RAG, và fine-tuning mô hình LLM.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Ai là đối tượng phù hợp tham gia khoá học Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Khoá học phù hợp cho các lập trình viên, nhà nghiên cứu AI, và những người quan tâm đến công nghệ Generative AI.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực kéo dài bao lâu?\",\n",
    "    \"answer\": \"Khoá học kéo dài khoảng 9 giờ, bao gồm cả lý thuyết và thực hành.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực có nội dung thực hành không?\",\n",
    "    \"answer\": \"Có, khoá học tập trung nhiều vào thực hành, chiếm hơn 70% thời lượng khóa học.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Trong khoá học Generative AI của Nguyễn Mạnh Lực có đề cập đến Langchain không?\",\n",
    "    \"answer\": \"Có, Langchain là một trong các nội dung chính của khoá học, giúp hiểu cách xây dựng ứng dụng AI.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có phù hợp cho người mới bắt đầu không?\",\n",
    "    \"answer\": \"Có, khoá học được thiết kế để phù hợp cho cả người mới bắt đầu lẫn người có kinh nghiệm.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Học phí của khoá học Generative AI của Nguyễn Mạnh Lực là bao nhiêu?\",\n",
    "    \"answer\": \"Học phí cụ thể sẽ được thông báo trên trang chính thức, nhưng rất cạnh tranh và hợp lý so với giá trị mang lại.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có cấp chứng chỉ không?\",\n",
    "    \"answer\": \"Có, bạn sẽ nhận được chứng chỉ hoàn thành khóa học sau khi hoàn tất các bài tập và bài kiểm tra cuối khoá.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực có cần kiến thức lập trình không?\",\n",
    "    \"answer\": \"Có, khoá học yêu cầu bạn có kiến thức cơ bản về Python trước khi tham gia.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có học trực tuyến không?\",\n",
    "    \"answer\": \"Có, khoá học được tổ chức hoàn toàn trực tuyến để tiện lợi cho học viên.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có phù hợp để phát triển kỹ năng thực tế không?\",\n",
    "    \"answer\": \"Có, khoá học tập trung vào các kỹ năng thực tế như fine-tuning mô hình và tích hợp Generative AI vào ứng dụng.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Tôi cần chuẩn bị gì trước khi tham gia khoá học Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Bạn cần chuẩn bị kiến thức cơ bản về Python và khả năng sử dụng máy tính cá nhân để thực hành.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực có áp dụng trong ngành công nghiệp không?\",\n",
    "    \"answer\": \"Có, các kiến thức từ khoá học có thể áp dụng trong nhiều ngành như tài chính, y tế, và giáo dục.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có tài liệu học không?\",\n",
    "    \"answer\": \"Có, tài liệu học và bài tập thực hành được cung cấp đầy đủ trong khoá học.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực có hỗ trợ sau khoá học không?\",\n",
    "    \"answer\": \"Có, học viên được hỗ trợ giải đáp thắc mắc và tiếp cận tài nguyên bổ sung sau khi hoàn thành khoá học.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Generative AI là gì, và nó được giảng dạy như thế nào trong khoá học Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Generative AI là công nghệ tạo ra nội dung mới từ dữ liệu. Trong khoá học, bạn sẽ học cách xây dựng và ứng dụng các mô hình Generative AI.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có phù hợp với nhà nghiên cứu không?\",\n",
    "    \"answer\": \"Có, khoá học cung cấp kiến thức chuyên sâu và các công cụ hiện đại, phù hợp cho các nhà nghiên cứu AI.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có bài tập nhóm không?\",\n",
    "    \"answer\": \"Không, nhưng có nhiều bài tập cá nhân để học viên thực hành và củng cố kiến thức.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực sẽ giúp tôi học gì về fine-tuning mô hình?\",\n",
    "    \"answer\": \"Bạn sẽ học cách điều chỉnh mô hình LLM để phù hợp với các tập dữ liệu cụ thể và tối ưu hoá hiệu suất.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có bao gồm phần hướng dẫn về RAG không?\",\n",
    "    \"answer\": \"Có, phần RAG giúp học viên hiểu cách kết hợp Generative AI với dữ liệu bên ngoài để tạo ra câu trả lời chính xác hơn.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Tại sao nên học khoá Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Khoá học không chỉ cung cấp kiến thức lý thuyết mà còn hướng dẫn thực hành áp dụng trực tiếp trong công việc.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có điểm gì đặc biệt so với các khoá học khác?\",\n",
    "    \"answer\": \"Khóa học kết hợp giữa lý thuyết, thực hành chuyên sâu và kinh nghiệm thực tế của giảng viên Nguyễn Mạnh Lực.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Ngôn ngữ sử dụng trong khoá học Generative AI của Nguyễn Mạnh Lực là gì?\",\n",
    "    \"answer\": \"Khoá học sử dụng tiếng Việt làm ngôn ngữ chính, nhưng có thể có tài liệu tham khảo bằng tiếng Anh.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Học viên cần máy tính cấu hình ra sao để tham gia khoá học Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Máy tính cần cấu hình trung bình với ít nhất 8GB RAM và CPU tốt để chạy các bài tập AI.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có đào tạo về LLM không?\",\n",
    "    \"answer\": \"Có, bạn sẽ học cách làm việc với Large Language Models và các ứng dụng thực tiễn của chúng.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có phù hợp với người làm kinh doanh không?\",\n",
    "    \"answer\": \"Có, khóa học giúp người làm kinh doanh hiểu và áp dụng Generative AI để tối ưu hóa quy trình và nâng cao hiệu suất.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Người học sẽ đạt được gì sau khi hoàn thành khoá học Generative AI của Nguyễn Mạnh Lực?\",\n",
    "    \"answer\": \"Bạn sẽ nắm vững kiến thức về Generative AI và có thể tự tin áp dụng vào các dự án thực tế.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khóa học Generative AI của Nguyễn Mạnh Lực có hỗ trợ xây dựng chatbot không?\",\n",
    "    \"answer\": \"Có, bạn sẽ được học cách tích hợp Generative AI vào xây dựng chatbot thông minh.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Khoá học Generative AI của Nguyễn Mạnh Lực có sử dụng các mô hình mã nguồn mở không?\",\n",
    "    \"answer\": \"Có, bạn sẽ được học cách sử dụng và tùy chỉnh các mô hình mã nguồn mở như GPT và BERT.\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1735288611237,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "tv2VzQmQEIq9"
   },
   "outputs": [],
   "source": [
    "questions = [item[\"question\"] for item in dataset]\n",
    "answers = [item[\"answer\"] for item in dataset]\n",
    "\n",
    "# Create a dictionary of lists\n",
    "dict_data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1735288611237,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "8qH6ZzYMEIyO",
    "outputId": "1683e1a5-4b9e-4c46-dd88-1709158ecd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 29\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_dict(dict_data)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "daa413a83f534cdb8ce5d41e0fe2e5bc",
      "a0ba698e241d47d49c34d8ca909dfa80",
      "86577e0527b94cdfaac29fa8fc970861",
      "8177beb385b9496398a016f13b631312",
      "3175a57a7b0a487ca3aac13c252cfe4c",
      "cc2b555126364edf827dc87d07467fdf",
      "1e6012e508c14279a2631935059b83b7",
      "11c67769394c4f0b92ebb1f98557c1df",
      "aa1b8455e22f415e87628ab3deedf433",
      "e15b43353d7f404b810c41d45a8b1fb0",
      "193f6d8427e442798db6fa2557198944"
     ]
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1735288611237,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "YqGO0aZHmxse",
    "outputId": "d028ee8c-dd35-4668-e8be-ef9e77e20df9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa413a83f534cdb8ce5d41e0fe2e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_instruction_prompt(example):\n",
    "    instruction = example['question']\n",
    "    response = example['answer']\n",
    "    example['text'] = f\"<s>Question: {instruction}\\nAnswer: {response}</s>\"\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(create_instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1735288611238,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "viCyyKzQmzvY",
    "outputId": "61f54d19-3249-4ebe-9439-f4a3bb779649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Hãy cho tôi biết nội dung của khoá học Generative AI của Nguyễn Mạnh Lực',\n",
       " 'answer': 'Khoá học bao gồm các chủ đề về Generative AI, large language models, langchain, RAG, và fine-tuning mô hình LLM.',\n",
       " 'text': '<s>Question: Hãy cho tôi biết nội dung của khoá học Generative AI của Nguyễn Mạnh Lực\\nAnswer: Khoá học bao gồm các chủ đề về Generative AI, large language models, langchain, RAG, và fine-tuning mô hình LLM.</s>'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Sz0w2M7n5M_"
   },
   "source": [
    "# 3.Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1735288611238,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "1et1DjAdol_e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fb7686045ddd4cf3b0f4b1ad21e8d1e4",
      "b14532471714421fa8eb555d9787dc4b",
      "ff36851e25b64c68b43914996f6dd5f9",
      "4842ede275d4400588c02d3b271bf213",
      "26099e8bbef14b6b97513c776d7ee88e",
      "fcacac691ef146db86f2029a812a2f2c",
      "45b2a8d17362417c81707ba66ecda4db",
      "4a79e2c4516b4e4eb551b41df0c42372",
      "9666aa483a8c404ab6dcc0c57ad085b8",
      "86fa6ff3a6d947eb89cfa7c06de78df6",
      "981d37e22e374e4fbbc70142ef562255"
     ]
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1735288611620,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "sa_q3QF4n14w",
    "outputId": "bb6469c4-6c1e-4b44-c1ec-a41ed1e239e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7686045ddd4cf3b0f4b1ad21e8d1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",  # 512\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Apply the tokenization function\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"question\", \"answer\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1735288611621,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "7_-oOaTNor7w",
    "outputId": "f8f87aa3-7242-4ac3-b5da-63b521fdf771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[0].get(\"input_ids\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGlp_tNnF_sE"
   },
   "source": [
    "# 4.Setup LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1735288611621,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "Ca_3XqSZF-mn"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1735288611939,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "c3Ojz1iDF-He",
    "outputId": "be1bcf3b-fcf2-4bc8-e8b4-63c7ce6ea39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,                # Rank of the LoRA updates\n",
    "    lora_alpha=32,      # Scaling factor\n",
    "    lora_dropout=0.1,   # Dropout to prevent overfitting\n",
    "    bias=\"none\",        # No bias adaptation\n",
    "    task_type=\"CAUSAL_LM\"  # Task type\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # Verify that only LoRA layers are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1735288611939,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "WzWT9OQwtuMR"
   },
   "outputs": [],
   "source": [
    "# Use the default data collator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # MLM (Masked Language Modeling) is False for causal LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1735288611939,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "NgW09mVaEJmW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BbMcrN-p_xB"
   },
   "source": [
    "# 5.Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1735288612396,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "rx6tqEqF9ygz"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1735288612814,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "OI7YCgw0qG-E",
    "outputId": "a9923850-d5fd-495a-f45a-6ef74361a999"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/01_Fine_TuningLLM/models/lora_finetuned_llama\",  # Directory to save checkpoints\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=100,            # Number of epochs\n",
    "    per_device_train_batch_size=4, # Adjust based on your GPU memory\n",
    "    gradient_accumulation_steps=4, # Accumulate gradients to reduce memory usage\n",
    "    evaluation_strategy=\"no\",      # No evaluation for small datasets\n",
    "    save_strategy=\"epoch\",         # Save model at the end of each epoch\n",
    "    learning_rate=3e-4,            # Learning rate for fine-tuning\n",
    "    fp16=True,                     # Enable mixed precision for faster training\n",
    "    logging_dir=\"./logs\",          # Directory for logs\n",
    "    logging_steps=50,              # Log every 50 steps\n",
    "    save_total_limit=2,            # Keep only 2 checkpoints\n",
    "    report_to=\"none\"               # Disable reporting (e.g., WandB)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1735288615310,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "nfloHzTVqJFW",
    "outputId": "ffa6e7e1-af85-4423-b428-514d2009fd52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-e67d5074adcf>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                           # LoRA-wrapped model\n",
    "    args=training_args,                    # Training arguments\n",
    "    train_dataset=tokenized_dataset,       # Tokenized dataset\n",
    "    data_collator=data_collator,           # Data collator\n",
    "    tokenizer=tokenizer                    # Tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 637877,
     "status": "ok",
     "timestamp": 1735289253183,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "yOBs6khyqTkH",
    "outputId": "cc4180c3-f7fc-423b-e6c2-63cb140bd93a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 10:32, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.177300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.213900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=2.2345990753173828, metrics={'train_runtime': 637.2308, 'train_samples_per_second': 4.551, 'train_steps_per_second': 0.314, 'total_flos': 8677154095104000.0, 'train_loss': 2.2345990753173828, 'epoch': 100.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1735289253527,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "TFaavJRusbKY"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/01_Fine_TuningLLM/models/lora_finetuned_llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1735289253528,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "PPwbHjx0sasb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSJWrOy5seNT"
   },
   "source": [
    "# 6.Load Fine-Tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1735289253528,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "L3LSGm4GsaJu"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 9687,
     "status": "ok",
     "timestamp": 1735289263212,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "4WOMs-a7som3"
   },
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir)\n",
    "fine_tuned_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/01_Fine_TuningLLM/models/lora_finetuned_llama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1735289265250,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "RO7Iu17AE0qF",
    "outputId": "b46027af-3f1e-4064-bf53-276f72271711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1735289267097,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "8MALtVFvquKb",
    "outputId": "bb55dda2-42cc-4051-c8c8-c717e34f6c20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Question: Hãy cho tôi biết nội dung của khoá học Generative AI của Nguyễn Mạnh Lực \n",
      "Answer: Khoá học bao gồm các chủ đề về Generative AI, large language models, langchain, RAG, và fine-tuning mô hình LLM.</s>\n"
     ]
    }
   ],
   "source": [
    "# Input prompt\n",
    "prompt = \"<s>Question: Hãy cho tôi biết nội dung của khoá học Generative AI của Nguyễn Mạnh Lực \\nAnswer:\"\n",
    "\n",
    "# Generate text\n",
    "response = generator(prompt, max_length=200, num_return_sequences=1, do_sample=True)\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1735289268743,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "qBsEJLBKwKc4",
    "outputId": "f8c64d0f-42b9-4b3c-cecc-331cd1265181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Question: Ai là đối tượng phù hợp tham gia khoá học Generative AI của Nguyễn Mạnh Lực? \n",
      "Answer: Khoá học phù hợp cho các lập trình viên, nhà nghiên cứu AI, và những người quan tâm đến công nghệ Generative AI.</s>\n"
     ]
    }
   ],
   "source": [
    "# Input prompt\n",
    "prompt = \"<s>Question: Ai là đối tượng phù hợp tham gia khoá học Generative AI của Nguyễn Mạnh Lực? \\nAnswer:\"\n",
    "\n",
    "# Generate text\n",
    "response = generator(prompt, max_length=200, num_return_sequences=1, do_sample=True)\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1735289268744,
     "user": {
      "displayName": "Luc Nguyen",
      "userId": "11685761023964702149"
     },
     "user_tz": -540
    },
    "id": "T-MdK7DvQQch"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11c67769394c4f0b92ebb1f98557c1df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193f6d8427e442798db6fa2557198944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e6012e508c14279a2631935059b83b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26099e8bbef14b6b97513c776d7ee88e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3175a57a7b0a487ca3aac13c252cfe4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45b2a8d17362417c81707ba66ecda4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4842ede275d4400588c02d3b271bf213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86fa6ff3a6d947eb89cfa7c06de78df6",
      "placeholder": "​",
      "style": "IPY_MODEL_981d37e22e374e4fbbc70142ef562255",
      "value": " 29/29 [00:00&lt;00:00, 369.90 examples/s]"
     }
    },
    "4a79e2c4516b4e4eb551b41df0c42372": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8177beb385b9496398a016f13b631312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e15b43353d7f404b810c41d45a8b1fb0",
      "placeholder": "​",
      "style": "IPY_MODEL_193f6d8427e442798db6fa2557198944",
      "value": " 29/29 [00:00&lt;00:00, 567.85 examples/s]"
     }
    },
    "86577e0527b94cdfaac29fa8fc970861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11c67769394c4f0b92ebb1f98557c1df",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa1b8455e22f415e87628ab3deedf433",
      "value": 29
     }
    },
    "86fa6ff3a6d947eb89cfa7c06de78df6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9666aa483a8c404ab6dcc0c57ad085b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "981d37e22e374e4fbbc70142ef562255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ba698e241d47d49c34d8ca909dfa80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc2b555126364edf827dc87d07467fdf",
      "placeholder": "​",
      "style": "IPY_MODEL_1e6012e508c14279a2631935059b83b7",
      "value": "Map: 100%"
     }
    },
    "aa1b8455e22f415e87628ab3deedf433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b14532471714421fa8eb555d9787dc4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcacac691ef146db86f2029a812a2f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_45b2a8d17362417c81707ba66ecda4db",
      "value": "Map: 100%"
     }
    },
    "cc2b555126364edf827dc87d07467fdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa413a83f534cdb8ce5d41e0fe2e5bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0ba698e241d47d49c34d8ca909dfa80",
       "IPY_MODEL_86577e0527b94cdfaac29fa8fc970861",
       "IPY_MODEL_8177beb385b9496398a016f13b631312"
      ],
      "layout": "IPY_MODEL_3175a57a7b0a487ca3aac13c252cfe4c"
     }
    },
    "e15b43353d7f404b810c41d45a8b1fb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb7686045ddd4cf3b0f4b1ad21e8d1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b14532471714421fa8eb555d9787dc4b",
       "IPY_MODEL_ff36851e25b64c68b43914996f6dd5f9",
       "IPY_MODEL_4842ede275d4400588c02d3b271bf213"
      ],
      "layout": "IPY_MODEL_26099e8bbef14b6b97513c776d7ee88e"
     }
    },
    "fcacac691ef146db86f2029a812a2f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff36851e25b64c68b43914996f6dd5f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a79e2c4516b4e4eb551b41df0c42372",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9666aa483a8c404ab6dcc0c57ad085b8",
      "value": 29
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
